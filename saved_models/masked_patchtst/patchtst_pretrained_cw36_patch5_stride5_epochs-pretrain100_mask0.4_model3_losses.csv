train_loss,valid_loss
1.046603,1.058065
1.000733,0.942828
0.902801,0.857842
0.940653,0.899552
0.934852,0.926375
0.885839,0.901949
0.922286,0.878158
0.919865,0.936832
0.933491,0.812277
0.870055,0.876915
0.900373,0.857850
0.863307,0.818884
0.813187,0.835543
0.888240,0.909264
0.903218,0.918522
0.859184,0.876980
0.840115,0.846690
0.868456,0.834455
0.864499,0.838141
0.898553,0.756800
0.859948,0.940263
0.848284,0.916463
0.829785,0.811948
0.874385,0.837524
0.809817,0.903430
0.826232,0.913246
0.848866,0.912989
0.810251,0.934718
0.420479,0.914295
0.852491,0.806971
0.859392,0.889275
0.836426,0.857800
0.825378,0.894127
0.835522,0.918290
0.883636,0.854322
0.863396,0.903604
0.812542,0.917891
0.877438,0.870502
0.827916,0.907512
0.821412,0.839092
0.796270,0.864936
0.885170,0.842447
0.867102,0.876614
0.844891,0.830661
0.842803,0.833038
0.835349,0.893716
0.811424,0.881087
0.850748,0.838527
0.837328,0.866965
0.871785,0.936434
0.842409,0.889582
0.883353,0.904963
0.892693,0.825306
0.880087,0.903146
0.853694,0.816586
0.872498,0.932341
0.885611,0.888271
0.860700,0.914475
0.836674,0.822516
0.871534,0.887962
0.860731,0.766946
0.843449,0.883499
0.816250,0.847784
0.854523,0.832285
0.847175,0.925954
0.812829,0.858707
0.851681,0.778626
0.859034,0.888560
0.851152,0.874283
0.854231,0.882158
0.824511,0.851681
0.834989,0.871020
0.876755,0.830194
0.871907,0.800318
0.837543,0.873485
0.815585,0.835703
0.871381,0.778774
0.905792,0.804360
0.824678,0.847471
0.852206,0.888598
0.815412,0.907130
0.818349,0.827202
0.870283,0.823301
0.784836,0.899444
0.880746,0.807909
0.834814,0.843453
0.857906,0.845576
0.828479,0.894380
0.829028,0.847568
0.870034,0.848326
0.829637,0.831412
0.827201,0.866458
0.847004,0.874191
0.874739,0.886747
0.832838,0.879422
0.853310,0.853092
0.857225,0.878374
0.820952,0.952168
0.873653,0.801011
0.845023,0.803005
